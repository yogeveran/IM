- ניצור סט המכיל את כל המצבים האפשריים.
- ניצור סט המכיל את כל הפעולות האפשריות.
- ניצור מיפוי של מצב לreward עבורו.
- ניצור מיפוי של מצב לכל הפעולות האפשריות עבורו.
- ניצור MDP ונשלח אליו את כל הפרמטרים הללו.
- ניצור ValueIteration עם פרמטר גמא=1.
- נפעיל את הפונקציה valueIteration ונשלח לו את אובייקט הMDP שיצרנו ופרמטר 0 בתור אפסילון.
- בשביל לדעת מה הreward בפוליסי האופטימלי נבדוק מה הערך שמתקבל עבור המצב ההתחלתי
	במילון שחזר לנו מהפונקציה valueIteration  
- על מנת לחלץ את הoptimal policy נקרא לפונקציה getOptimalActionForState ונשלח לה את המצב 
	הנוכחי.
